{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f44b5b0-f8ba-44a9-87e5-10ea895601f5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b078888-89ff-480e-8ba0-aed18a243e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*'dropout_adj' is deprecated, use 'dropout_edge' instead.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3b8846-26c4-4b65-b231-a91c76dba465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b282aa-6c67-4bda-b42d-f50922f1dcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "adj = sp.load_npz('../CSE881_data_2024/adj.npz')\n",
    "features  = np.load('../CSE881_data_2024/features.npy')\n",
    "labels = np.load('../CSE881_data_2024/labels.npy')\n",
    "splits = json.load(open('../CSE881_data_2024/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cec296-91e8-4c19-a07c-247f5521a7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10100 edges in total in the graph\n",
      "\n",
      "tensor([1.])\n",
      "These edges are not weighted.\n"
     ]
    }
   ],
   "source": [
    "# transfer adjacency matrix into edge index\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "edge_index = from_scipy_sparse_matrix(adj)\n",
    "print(\"There are\", edge_index[0].size(1), \"edges in total in the graph\\n\")\n",
    "\n",
    "print(torch.unique(edge_index[1]))\n",
    "print(\"These edges are not weighted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48aba824-8a75-4e6c-b9e5-cdd7806172d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2480 nodes in the graph.\n",
      "Each node can be one of 7 classes.\n",
      "Training set size: 496\n",
      "Test set size: 1984\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(features), \"nodes in the graph.\")\n",
    "num_classes = len(np.unique(labels))\n",
    "print(\"Each node can be one of\", num_classes, \"classes.\")\n",
    "print(\"Training set size:\", len(idx_train))\n",
    "print(\"Test set size:\", len(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b743263-a811-4f48-bd0c-ea1dfa407d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136d32c6-ae9d-4c59-957b-21641468fd57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1390\n"
     ]
    }
   ],
   "source": [
    "features = torch.from_numpy(features).float()\n",
    "num_features = len(features[0])\n",
    "print(\"Number of features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0a8f6c-bebf-49c5-a66c-ec842cbfed9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = features.to(device)\n",
    "edge_index = edge_index[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7d16f-36fb-483f-bb3f-ffa1063fd704",
   "metadata": {},
   "source": [
    "### Supurvised Contrastive Learning Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46408102-4ba8-476a-9e0c-baf18123335f",
   "metadata": {},
   "source": [
    "Method 'GRACE': Zhu et al., Deep Graph Contrastive Representation Learning, GRL+@ICML, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d38b3-16d7-47a1-b726-8bb8b11150c3",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2006.04131"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac53a84-1022-4ae7-bea2-5edffe136929",
   "metadata": {},
   "source": [
    "Method 'SupCon': P. Khosla et al., Supervised Contrastive Learning, NeurIPS, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca794ac-460b-46d2-8c8a-9c620df143e3",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2004.11362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7154e4b-bdd9-43a4-9083-6de21c949e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import GCL.augmentors as A\n",
    "import GCL.losses as L\n",
    "from GCL.models import DualBranchContrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf7e5dd-1730-4751-b56a-72dd6dced667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, augmentor):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.augmentor = augmentor\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        aug1, aug2 = self.augmentor\n",
    "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
    "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
    "        z = self.encoder(x, edge_index)\n",
    "        z1 = self.encoder(x1, edge_index1)\n",
    "        z2 = self.encoder(x2, edge_index2)\n",
    "        return z, z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4905cc4b-9dc6-4ff9-97d8-fb85d9a6b2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contrastive_mask(idx_train_sub, train_labels_sub):\n",
    "    \n",
    "    num_nodes = len(features)\n",
    "\n",
    "    # create extra_pos_mask\n",
    "    # initialize a 2480 x 2480 matrix of False\n",
    "    extra_pos_mask = torch.zeros((num_nodes, num_nodes), dtype=torch.bool).to(device)\n",
    "\n",
    "    # create a temporary full label tensor initialized with a dummy label and place the known labels\n",
    "    full_labels = torch.full((num_nodes,), -1, dtype=train_labels_sub.dtype).to(device)\n",
    "    full_labels[idx_train_sub] = train_labels_sub\n",
    "\n",
    "    # iterate through each known label and update the label_matrix to True by finding nodes with the same label\n",
    "    for i, label in zip(idx_train_sub, train_labels_sub):\n",
    "        same_label_indices = torch.where(full_labels == label)[0]\n",
    "        extra_pos_mask[i, same_label_indices] = True\n",
    "        extra_pos_mask[same_label_indices, i] = True\n",
    "    extra_pos_mask.fill_diagonal_(False)\n",
    "\n",
    "    # pos_mask: [N, 2N] for both inter-view and intra-view samples\n",
    "    extra_pos_mask = torch.cat([extra_pos_mask, extra_pos_mask], dim=1).to(device)\n",
    "    # fill inter-view positives only; pos_mask for intra-view samples should have False in diagonal\n",
    "    extra_pos_mask.fill_diagonal_(True)\n",
    "\n",
    "    # create extra_neg_mask\n",
    "    # initialize a 2480 x 2480 matrix of True\n",
    "    extra_neg_mask = torch.ones((num_nodes, num_nodes), dtype=torch.bool).to(device)\n",
    "\n",
    "    # iterate through each known label and update the label_matrix to False by finding nodes with the same label\n",
    "    for i, label in zip(idx_train_sub, train_labels_sub):\n",
    "        same_label_indices = torch.where(full_labels == label)[0]\n",
    "        extra_neg_mask[i, same_label_indices] = False\n",
    "        extra_neg_mask[same_label_indices, i] = False\n",
    "\n",
    "    # set the diagonal to False since a sample cannot be a negative of itself\n",
    "    extra_neg_mask.fill_diagonal_(False)\n",
    "\n",
    "    # neg_mask: [N, 2N] for both inter-view and intra-view samples\n",
    "    extra_neg_mask = torch.cat([extra_neg_mask, extra_neg_mask], dim=1).to(device)\n",
    "    \n",
    "    return extra_pos_mask, extra_neg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b04ffe-fb7e-4881-8c20-105b307beea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augumentation of the graph\n",
    "aug1 = A.Compose([A.EdgeRemoving(pe=0.1), A.FeatureDropout(pf=0.1), A.NodeDropping(pn=0.1)])\n",
    "aug2 = A.Compose([A.EdgeRemoving(pe=0.1), A.FeatureDropout(pf=0.1), A.NodeDropping(pn=0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36af2c84-221e-4684-938d-0616ea7ed66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# contrastive loss function\n",
    "contrast_loss = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='L2L', intraview_negs=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73852b5d-71d8-4cf0-9258-dd2a233b3ed8",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5fe789-2fa3-47b1-9216-44f92ff3f41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e01b66-cd07-4227-bd7e-565c554b2ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    def __init__(self, model_structure, optimizer_lr, scheduler_factor, scheduler_patience, \n",
    "                 epoches, lambda_reg, output_interval=4, features=features, edge_index=edge_index,\n",
    "                 labels=labels, idx=idx_train, method='SupCon'):\n",
    "        \"\"\"\n",
    "        Used for hyperparameter tuning with spliting 20% of training set as validation set\n",
    "        \n",
    "        :param model_structure: The function to define model structure\n",
    "        :param optimizer_lr: The initial learning rate for the optimizer\n",
    "        :param scheduler_factor: The factor by which the learning rate will be reduced\n",
    "        :param scheduler_patience: The number of epochs with no improvement after which learning rate will be reduced\n",
    "        :param epoches: The number of epoches to train\n",
    "        :param lambda_reg: Hyperparameter to control ratio of contrastive loss\n",
    "        :param output_interval: The interval to ouput the training result\n",
    "        :param features: The features of the dataset\n",
    "        :param edge_index: The edge index tensor describing graph connectivity\n",
    "        :param labels: The labels for data points in the dataset\n",
    "        :param idx: Indices of the dataset to be used for splitting to train_set_sub and validation set\n",
    "        :param method: Contrastive learning method: SupCon or GRACE\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_structure = model_structure\n",
    "        self.model = self.model_structure() \n",
    "        \n",
    "        self.optimizer_lr = optimizer_lr\n",
    "        self.scheduler_factor = scheduler_factor\n",
    "        self.scheduler_patience = scheduler_patience\n",
    "        self.epoches = epoches\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        self.output_interval = output_interval\n",
    "        self.features = features\n",
    "        self.edge_index = edge_index\n",
    "        self.labels = labels\n",
    "        self.idx = idx\n",
    "        self.method = method\n",
    "     \n",
    "        # Splitting the dataset into training and validation sets\n",
    "        self.idx_train_sub, self.idx_val, train_labels_sub, val_labels = train_test_split(\n",
    "            idx, labels, test_size=0.2, random_state=123, stratify=labels)\n",
    "        \n",
    "        # Converting labels to tensor\n",
    "        self.train_labels_sub = torch.from_numpy(train_labels_sub).long().to(device)\n",
    "        self.val_labels = torch.from_numpy(val_labels).long().to(device)\n",
    "        \n",
    "        self.encoder_model = Encoder(encoder=self.model, augmentor=(aug1, aug2)).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.encoder_model.parameters(), optimizer_lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=scheduler_factor, patience=scheduler_patience)\n",
    "        \n",
    "        self.supervised_criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.contrast_criterion = contrast_loss\n",
    "        self.extra_pos_mask, self.extra_neg_mask = contrastive_mask(self.idx_train_sub, self.train_labels_sub)\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model on the training dataset.\n",
    "        \"\"\"\n",
    "        self.encoder_model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        z, z1, z2 = self.encoder_model(self.features, self.edge_index)\n",
    "        \n",
    "        if self.method == 'SupCon':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2, extra_pos_mask=self.extra_pos_mask, extra_neg_mask=self.extra_neg_mask)\n",
    "        elif self.method == 'GRACE':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method specified. Please choose 'SupCon' or 'GRACE'.\")\n",
    "        supervised_loss = self.supervised_criterion(z[self.idx_train_sub], self.train_labels_sub)\n",
    "        \n",
    "        total_loss = supervised_loss + self.lambda_reg * contrast_loss\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return contrast_loss, supervised_loss\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the validation subset.\n",
    "        \"\"\"\n",
    "        self.encoder_model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.encoder_model(self.features, self.edge_index)\n",
    "            pred = out[0].argmax(dim=1)\n",
    "            \n",
    "            train_correct = pred[self.idx_train_sub] == self.train_labels_sub\n",
    "            train_acc = int(train_correct.sum()) / len(self.idx_train_sub)\n",
    "            \n",
    "            val_correct = pred[self.idx_val] == self.val_labels\n",
    "            val_acc = int(val_correct.sum()) / len(self.idx_val)\n",
    "            \n",
    "            val_loss = self.supervised_criterion(out[0][self.idx_val], self.val_labels).item()\n",
    "            \n",
    "        return train_acc, val_acc, val_loss\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executes the training and validation process, adjusting the learning rate and lambda as needed.\n",
    "        \"\"\"   \n",
    "        for epoch in range(self.epoches):\n",
    "            contrast_loss, supervised_loss = self.train()\n",
    "            train_acc, val_acc, val_loss = self.test()\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            if epoch % self.output_interval == 0:\n",
    "                print(f'Epoch: {epoch:03d}, Con Loss: {contrast_loss:.2f}, Sup Loss: {supervised_loss:.2f}, Train Acc: {train_acc:.2f}, Val Loss: {val_loss:.2f}, Val Acc: {val_acc:.2f}')\n",
    "\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "    tuner = HyperparameterTuner(model_structure, optimizer_lr=0.001, \n",
    "    scheduler_factor=0.1, scheduler_patience=10, epoches=100, lambda=0.9,\n",
    "    output_interval=4, features=features, edge_index_tensor=edge_index_tensor, \n",
    "    labels=labels, idx=idx_train, method='SupCon')\n",
    "    tuner.run()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e7282-bbaf-415b-9022-fcf1f1174be4",
   "metadata": {},
   "source": [
    "### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb33551f-e75a-4cb9-9736-7e4577fe7541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af323d8-663f-4031-a763-d9b49a7d14dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model_structure, optimizer_lr, scheduler_factor, scheduler_patience, \n",
    "                 epoches, lambda_reg, features=features, edge_index=edge_index, labels=labels, \n",
    "                 idx=idx_train, n_folds=5, device='cuda', method='SupCon'):\n",
    "        \"\"\"\n",
    "        5-fold cross-validation to evaluate the model with multiple rounds\n",
    "        \n",
    "        :param model_structure: The function to define model structure\n",
    "        :param optimizer_lr: The initial learning rate for the optimizer\n",
    "        :param scheduler_factor: The factor by which the learning rate will be reduced\n",
    "        :param scheduler_patience: The number of epochs with no improvement after which learning rate will be reduced\n",
    "        :param epoches: The number of epoch to train\n",
    "        :param lambda_reg: Hyperparameter to control ratio of contrastive loss\n",
    "        :param features: The features of the dataset\n",
    "        :param edge_index: The edge index tensor describing graph connectivity\n",
    "        :param labels: The labels for data points in the dataset\n",
    "        :param idx: Indices of the dataset to be used for splitting to train_set_sub and validation set\n",
    "        :param cv_rounds: The round of cross-validation\n",
    "        :param n_folds: Number of folds for cross-validation\n",
    "        :param method: Contrastive learning method: SupCon or GRACE\n",
    "\n",
    "        \"\"\"\n",
    "        self.model_structure = model_structure\n",
    "        \n",
    "        self.optimizer_lr = optimizer_lr\n",
    "        self.scheduler_factor = scheduler_factor\n",
    "        self.scheduler_patience = scheduler_patience\n",
    "        self.epoches = epoches\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        self.features = features\n",
    "        self.edge_index = edge_index\n",
    "        self.labels = np.array(labels)\n",
    "        self.idx = np.array(idx)\n",
    "        \n",
    "        self.n_folds = n_folds\n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder_models = []\n",
    "        \n",
    "        self.supervised_criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.contrast_criterion = contrast_loss\n",
    "        self.method = method\n",
    "        \n",
    "        \n",
    "    def train(self, encoder_model, optimizer, features, edge_index, \n",
    "              train_labels_sub, idx_train_sub, extra_pos_mask, extra_neg_mask):\n",
    "        \"\"\"\n",
    "        Trains the model on the training dataset.\n",
    "        \"\"\"\n",
    "        encoder_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z, z1, z2 = encoder_model(features, edge_index)\n",
    "        \n",
    "        if self.method == 'SupCon':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2, extra_pos_mask=extra_pos_mask, extra_neg_mask=extra_neg_mask)\n",
    "        elif self.method == 'GRACE':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method specified. Please choose 'SupCon' or 'GRACE'.\")\n",
    "        supervised_loss = self.supervised_criterion(z[idx_train_sub], train_labels_sub)\n",
    "        \n",
    "        total_loss = supervised_loss + self.lambda_reg * contrast_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return contrast_loss, supervised_loss\n",
    "    \n",
    "    \n",
    "    def test(self, encoder_model, features, edge_index, val_labels, idx_val):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the validation subset.\n",
    "        \"\"\"\n",
    "        encoder_model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = encoder_model(features, edge_index)\n",
    "            pred = out[0].argmax(dim=1)\n",
    "            \n",
    "            val_correct = pred[idx_val] == val_labels\n",
    "            val_acc = int(val_correct.sum()) / len(idx_val)\n",
    "            \n",
    "            val_loss = self.supervised_criterion(out[0][idx_val], val_labels).item()\n",
    "            \n",
    "        return val_acc, val_loss\n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Cross-validation to evaluate the model, print accuracy of each model, \n",
    "        average accuracy per round, and overall average accuracy. \n",
    "        Models and their accuracies are saved in a dictionary.\n",
    "        \"\"\"       \n",
    "        cv_acc = []\n",
    "        cv_loss = []\n",
    "            \n",
    "        kf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        fold_count = 0\n",
    "        for train_index_sub, val_index in kf.split(self.idx, self.labels):\n",
    "            fold_count += 1\n",
    "                \n",
    "            # Create CV idx and labels for current round\n",
    "            idx_train_sub, idx_val = self.idx[train_index_sub], self.idx[val_index]\n",
    "            train_labels_sub, val_labels = self.labels[train_index_sub], self.labels[val_index]\n",
    "                \n",
    "            train_labels_sub = torch.from_numpy(train_labels_sub).long().to(self.device)\n",
    "            val_labels = torch.from_numpy(val_labels).long().to(self.device)\n",
    "                \n",
    "            cur_extra_pos_mask, cur_extra_neg_mask = contrastive_mask(idx_train_sub, train_labels_sub)\n",
    "                \n",
    "            # Instantiate a new encoder model for each fold\n",
    "            cur_model = self.model_structure().to(self.device) \n",
    "            cur_encoder_model = Encoder(encoder=cur_model, augmentor=(aug1, aug2)).to(device)\n",
    "                \n",
    "            # Setting up the optimizer, scheduler, and loss function\n",
    "            cur_optimizer = torch.optim.Adam(cur_encoder_model.parameters(), lr=self.optimizer_lr)\n",
    "            cur_scheduler = ReduceLROnPlateau(cur_optimizer, mode='min', factor=self.scheduler_factor, patience=self.scheduler_patience)\n",
    "                \n",
    "            for epoch in range(self.epoches):\n",
    "                contrast_loss, supervised_loss = self.train(cur_encoder_model, cur_optimizer, \n",
    "                                        self.features, self.edge_index, train_labels_sub, \n",
    "                                        idx_train_sub, cur_extra_pos_mask, cur_extra_neg_mask)\n",
    "                val_acc, val_loss = self.test(cur_encoder_model, self.features, \n",
    "                                                self.edge_index, val_labels, idx_val)\n",
    "                cur_scheduler.step(val_loss)\n",
    "                \n",
    "            cv_acc.append(val_acc)\n",
    "            cv_loss.append(val_loss)\n",
    "            print(f\"Fold {fold_count} - Val Accuracy: {val_acc:.3f}, Val Loss: {val_loss:.3f}\")\n",
    "                \n",
    "        avg_val_acc = np.mean(cv_acc)\n",
    "        avg_val_loss = np.mean(cv_loss)\n",
    "        print(f\"Average Val Accuracy: {avg_val_acc:.4f}, Average Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "    evaluator = HyperparameterTuner(model_structure, optimizer_lr=0.001, \n",
    "    scheduler_factor=0.1, scheduler_patience=10, epochs=100, lambda_reg=0.9,\n",
    "    features=features, edge_index_tensor=edge_index_tensor, \n",
    "    labels=labels, idx=idx_train, n_folds=5, method='SupCon')\n",
    "    models = evaluator.evaluate()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324aa4a5-1281-4e3d-a014-33309702d59e",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be66fee1-2315-4090-b3ba-3b6cf4dddd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a396bdaf-f90e-4bbe-8710-b7ec91ad4c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GCN_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GCN(in_channels=num_features, hidden_channels=512, \n",
    "               out_channels=num_classes, num_layers=3, dropout=0.5, act='relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "352064e5-e57b-47d7-8ef9-a0b60b7a0aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.22, Sup Loss: 1.94, Train Acc: 0.15, Val Loss: 1.94, Val Acc: 0.15\n",
      "Epoch: 008, Con Loss: 8.51, Sup Loss: 1.93, Train Acc: 0.15, Val Loss: 1.94, Val Acc: 0.15\n",
      "Epoch: 016, Con Loss: 8.51, Sup Loss: 1.87, Train Acc: 0.15, Val Loss: 1.88, Val Acc: 0.15\n",
      "Epoch: 024, Con Loss: 8.50, Sup Loss: 1.78, Train Acc: 0.15, Val Loss: 1.79, Val Acc: 0.15\n",
      "Epoch: 032, Con Loss: 8.49, Sup Loss: 1.67, Train Acc: 0.42, Val Loss: 1.69, Val Acc: 0.34\n",
      "Epoch: 040, Con Loss: 8.45, Sup Loss: 1.54, Train Acc: 0.57, Val Loss: 1.56, Val Acc: 0.50\n",
      "Epoch: 048, Con Loss: 8.34, Sup Loss: 1.36, Train Acc: 0.64, Val Loss: 1.39, Val Acc: 0.59\n",
      "Epoch: 056, Con Loss: 8.13, Sup Loss: 1.17, Train Acc: 0.68, Val Loss: 1.21, Val Acc: 0.62\n",
      "Epoch: 064, Con Loss: 8.03, Sup Loss: 0.99, Train Acc: 0.71, Val Loss: 1.03, Val Acc: 0.66\n",
      "Epoch: 072, Con Loss: 7.88, Sup Loss: 0.85, Train Acc: 0.73, Val Loss: 0.91, Val Acc: 0.69\n",
      "Epoch: 080, Con Loss: 7.82, Sup Loss: 0.76, Train Acc: 0.77, Val Loss: 0.83, Val Acc: 0.71\n",
      "Epoch: 088, Con Loss: 7.73, Sup Loss: 0.68, Train Acc: 0.85, Val Loss: 0.75, Val Acc: 0.77\n",
      "Epoch: 096, Con Loss: 7.70, Sup Loss: 0.61, Train Acc: 0.86, Val Loss: 0.70, Val Acc: 0.80\n",
      "Epoch: 104, Con Loss: 7.67, Sup Loss: 0.56, Train Acc: 0.86, Val Loss: 0.67, Val Acc: 0.81\n",
      "Epoch: 112, Con Loss: 7.65, Sup Loss: 0.51, Train Acc: 0.86, Val Loss: 0.63, Val Acc: 0.83\n",
      "Epoch: 120, Con Loss: 7.62, Sup Loss: 0.47, Train Acc: 0.86, Val Loss: 0.61, Val Acc: 0.83\n",
      "Epoch: 128, Con Loss: 7.56, Sup Loss: 0.43, Train Acc: 0.88, Val Loss: 0.58, Val Acc: 0.83\n",
      "Epoch: 136, Con Loss: 7.49, Sup Loss: 0.40, Train Acc: 0.89, Val Loss: 0.55, Val Acc: 0.84\n",
      "Epoch: 144, Con Loss: 7.57, Sup Loss: 0.36, Train Acc: 0.90, Val Loss: 0.54, Val Acc: 0.84\n",
      "Epoch: 152, Con Loss: 7.49, Sup Loss: 0.34, Train Acc: 0.92, Val Loss: 0.52, Val Acc: 0.88\n",
      "Epoch: 160, Con Loss: 7.49, Sup Loss: 0.33, Train Acc: 0.93, Val Loss: 0.50, Val Acc: 0.87\n",
      "Epoch: 168, Con Loss: 7.48, Sup Loss: 0.30, Train Acc: 0.94, Val Loss: 0.49, Val Acc: 0.86\n",
      "Epoch: 176, Con Loss: 7.48, Sup Loss: 0.28, Train Acc: 0.93, Val Loss: 0.49, Val Acc: 0.86\n",
      "Epoch: 184, Con Loss: 7.38, Sup Loss: 0.27, Train Acc: 0.93, Val Loss: 0.48, Val Acc: 0.86\n",
      "Epoch: 192, Con Loss: 7.40, Sup Loss: 0.26, Train Acc: 0.93, Val Loss: 0.47, Val Acc: 0.87\n",
      "Epoch: 200, Con Loss: 7.44, Sup Loss: 0.24, Train Acc: 0.93, Val Loss: 0.47, Val Acc: 0.86\n",
      "Epoch: 208, Con Loss: 7.46, Sup Loss: 0.25, Train Acc: 0.93, Val Loss: 0.46, Val Acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(GCN_model, optimizer_lr=0.0005, epoches=210, scheduler_factor=0.1, \n",
    "                            scheduler_patience=1000, lambda_reg=2, output_interval=8)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d0a659-d795-4080-a0ea-d8653552cde0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.830, Val Loss: 0.533\n",
      "Fold 2 - Val Accuracy: 0.838, Val Loss: 0.546\n",
      "Fold 3 - Val Accuracy: 0.869, Val Loss: 0.380\n",
      "Fold 4 - Val Accuracy: 0.859, Val Loss: 0.473\n",
      "Fold 5 - Val Accuracy: 0.848, Val Loss: 0.568\n",
      "Average Val Accuracy: 0.8488, Average Val Loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(GCN_model, optimizer_lr=0.0005, epoches=210, scheduler_factor=0.1, \n",
    "                            scheduler_patience=1000, lambda_reg=2)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e4f85-fa21-4f55-bae5-c4785f5941c3",
   "metadata": {},
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4858d5f8-f4fb-4db7-8bbe-e15f6317f05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0ab3ee2-f4d2-45dc-9baa-7c9fb18a9273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GraphSAGE_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GraphSAGE(in_channels=num_features, hidden_channels=256, \n",
    "               out_channels=num_classes, num_layers=3, dropout=0.5, act='relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b07b72b-6f7a-4379-aba3-917012e4bdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.13, Sup Loss: 1.96, Train Acc: 0.05, Val Loss: 1.96, Val Acc: 0.05\n",
      "Epoch: 008, Con Loss: 8.54, Sup Loss: 1.99, Train Acc: 0.11, Val Loss: 1.99, Val Acc: 0.10\n",
      "Epoch: 016, Con Loss: 8.52, Sup Loss: 1.97, Train Acc: 0.11, Val Loss: 1.98, Val Acc: 0.09\n",
      "Epoch: 024, Con Loss: 8.51, Sup Loss: 1.95, Train Acc: 0.11, Val Loss: 1.95, Val Acc: 0.09\n",
      "Epoch: 032, Con Loss: 8.51, Sup Loss: 1.91, Train Acc: 0.19, Val Loss: 1.93, Val Acc: 0.11\n",
      "Epoch: 040, Con Loss: 8.50, Sup Loss: 1.87, Train Acc: 0.28, Val Loss: 1.89, Val Acc: 0.21\n",
      "Epoch: 048, Con Loss: 8.49, Sup Loss: 1.82, Train Acc: 0.54, Val Loss: 1.84, Val Acc: 0.33\n",
      "Epoch: 056, Con Loss: 8.47, Sup Loss: 1.72, Train Acc: 0.73, Val Loss: 1.76, Val Acc: 0.56\n",
      "Epoch: 064, Con Loss: 8.33, Sup Loss: 1.57, Train Acc: 0.84, Val Loss: 1.61, Val Acc: 0.75\n",
      "Epoch: 072, Con Loss: 8.12, Sup Loss: 1.33, Train Acc: 0.88, Val Loss: 1.39, Val Acc: 0.81\n",
      "Epoch: 080, Con Loss: 8.06, Sup Loss: 1.06, Train Acc: 0.89, Val Loss: 1.12, Val Acc: 0.81\n",
      "Epoch: 088, Con Loss: 8.04, Sup Loss: 0.77, Train Acc: 0.88, Val Loss: 0.87, Val Acc: 0.80\n",
      "Epoch: 096, Con Loss: 7.90, Sup Loss: 0.58, Train Acc: 0.89, Val Loss: 0.69, Val Acc: 0.79\n",
      "Epoch: 104, Con Loss: 7.89, Sup Loss: 0.45, Train Acc: 0.89, Val Loss: 0.60, Val Acc: 0.80\n",
      "Epoch: 112, Con Loss: 7.83, Sup Loss: 0.37, Train Acc: 0.91, Val Loss: 0.55, Val Acc: 0.83\n",
      "Epoch: 120, Con Loss: 7.82, Sup Loss: 0.32, Train Acc: 0.92, Val Loss: 0.53, Val Acc: 0.83\n",
      "Epoch: 128, Con Loss: 7.70, Sup Loss: 0.28, Train Acc: 0.93, Val Loss: 0.52, Val Acc: 0.85\n",
      "Epoch: 136, Con Loss: 7.78, Sup Loss: 0.25, Train Acc: 0.93, Val Loss: 0.51, Val Acc: 0.84\n",
      "Epoch: 144, Con Loss: 7.74, Sup Loss: 0.22, Train Acc: 0.94, Val Loss: 0.51, Val Acc: 0.84\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(GraphSAGE_model, optimizer_lr=0.0003, epoches=145, scheduler_factor=0.2, \n",
    "                            scheduler_patience=1000, output_interval=8, lambda_reg=0.8)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ef3935-b61f-4a4d-994e-dde0fb08c96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.810, Val Loss: 0.506\n",
      "Fold 2 - Val Accuracy: 0.808, Val Loss: 0.642\n",
      "Fold 3 - Val Accuracy: 0.889, Val Loss: 0.368\n",
      "Fold 4 - Val Accuracy: 0.848, Val Loss: 0.485\n",
      "Fold 5 - Val Accuracy: 0.869, Val Loss: 0.572\n",
      "Average Val Accuracy: 0.8448, Average Val Loss: 0.5148\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(GraphSAGE_model, optimizer_lr=0.0003, epoches=145, scheduler_factor=0.2, \n",
    "                            scheduler_patience=1000, lambda_reg=0.8)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7ab93-db34-4320-8b37-faec30960d03",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa5964c-cbdf-40e7-b555-d5cce3daa8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2f7af1-3c03-4529-8364-62472a5056ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout) \n",
    "        self.gat2 = GATConv(hidden_channels*heads, hidden_channels, heads=heads, dropout=dropout) \n",
    "        self.gat3 = GATConv(hidden_channels*heads, out_channels, concat=False,\n",
    "                             heads=1, dropout=dropout)  \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gat3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd53b4a-17f0-4305-aa16-0cbc62dc0167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GAT_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GAT(in_channels=num_features, hidden_channels=32, \n",
    "               out_channels=num_classes, heads=16, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "542a75f0-6e67-4083-b051-6949a80b56e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.27, Sup Loss: 2.07, Train Acc: 0.34, Val Loss: 1.89, Val Acc: 0.33\n",
      "Epoch: 003, Con Loss: 10.00, Sup Loss: 1.83, Train Acc: 0.41, Val Loss: 1.68, Val Acc: 0.38\n",
      "Epoch: 006, Con Loss: 9.72, Sup Loss: 1.64, Train Acc: 0.59, Val Loss: 1.50, Val Acc: 0.51\n",
      "Epoch: 009, Con Loss: 9.68, Sup Loss: 1.52, Train Acc: 0.76, Val Loss: 1.35, Val Acc: 0.68\n",
      "Epoch: 012, Con Loss: 9.59, Sup Loss: 1.37, Train Acc: 0.81, Val Loss: 1.21, Val Acc: 0.78\n",
      "Epoch: 015, Con Loss: 9.57, Sup Loss: 1.35, Train Acc: 0.82, Val Loss: 1.08, Val Acc: 0.79\n",
      "Epoch: 018, Con Loss: 9.58, Sup Loss: 1.17, Train Acc: 0.84, Val Loss: 0.95, Val Acc: 0.78\n",
      "Epoch: 021, Con Loss: 9.51, Sup Loss: 1.13, Train Acc: 0.86, Val Loss: 0.85, Val Acc: 0.80\n",
      "Epoch: 024, Con Loss: 9.56, Sup Loss: 1.12, Train Acc: 0.88, Val Loss: 0.76, Val Acc: 0.83\n",
      "Epoch: 027, Con Loss: 9.49, Sup Loss: 1.04, Train Acc: 0.89, Val Loss: 0.68, Val Acc: 0.85\n",
      "Epoch: 030, Con Loss: 9.39, Sup Loss: 0.97, Train Acc: 0.91, Val Loss: 0.63, Val Acc: 0.85\n",
      "Epoch: 033, Con Loss: 9.45, Sup Loss: 0.96, Train Acc: 0.91, Val Loss: 0.59, Val Acc: 0.85\n",
      "Epoch: 036, Con Loss: 9.44, Sup Loss: 0.95, Train Acc: 0.92, Val Loss: 0.56, Val Acc: 0.85\n",
      "Epoch: 039, Con Loss: 9.33, Sup Loss: 0.91, Train Acc: 0.92, Val Loss: 0.54, Val Acc: 0.86\n",
      "Epoch: 042, Con Loss: 9.34, Sup Loss: 0.91, Train Acc: 0.91, Val Loss: 0.52, Val Acc: 0.85\n",
      "Epoch: 045, Con Loss: 9.30, Sup Loss: 0.86, Train Acc: 0.92, Val Loss: 0.51, Val Acc: 0.85\n",
      "Epoch: 048, Con Loss: 9.31, Sup Loss: 0.81, Train Acc: 0.92, Val Loss: 0.50, Val Acc: 0.86\n",
      "Epoch: 051, Con Loss: 9.34, Sup Loss: 0.83, Train Acc: 0.92, Val Loss: 0.49, Val Acc: 0.85\n",
      "Epoch: 054, Con Loss: 9.37, Sup Loss: 0.76, Train Acc: 0.93, Val Loss: 0.49, Val Acc: 0.86\n",
      "Epoch: 057, Con Loss: 9.22, Sup Loss: 0.79, Train Acc: 0.93, Val Loss: 0.49, Val Acc: 0.86\n",
      "Epoch: 060, Con Loss: 9.25, Sup Loss: 0.75, Train Acc: 0.93, Val Loss: 0.48, Val Acc: 0.88\n",
      "Epoch: 063, Con Loss: 9.24, Sup Loss: 0.84, Train Acc: 0.94, Val Loss: 0.48, Val Acc: 0.87\n",
      "Epoch: 066, Con Loss: 9.29, Sup Loss: 0.75, Train Acc: 0.95, Val Loss: 0.47, Val Acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(GAT_model, optimizer_lr=0.0008, epoches=67, scheduler_factor=0.3, \n",
    "                            scheduler_patience=1000, output_interval=3, lambda_reg=0)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd3950b5-8bbf-4499-a805-b02e39eff484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.820, Val Loss: 0.513\n",
      "Fold 2 - Val Accuracy: 0.818, Val Loss: 0.614\n",
      "Fold 3 - Val Accuracy: 0.848, Val Loss: 0.395\n",
      "Fold 4 - Val Accuracy: 0.869, Val Loss: 0.467\n",
      "Fold 5 - Val Accuracy: 0.848, Val Loss: 0.527\n",
      "Average Val Accuracy: 0.8408, Average Val Loss: 0.5033\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(GAT_model, optimizer_lr=0.0008, epoches=67, scheduler_factor=0.3, \n",
    "                            scheduler_patience=1000, lambda_reg=0)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33f12f-06a7-438f-ba81-accd16ce02f9",
   "metadata": {},
   "source": [
    "### GAT - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a4dcc59-b431-4c64-b339-8e3cab59eddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfee795d-feb2-40e6-bcfb-a22749090fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.gatv21 = GATv2Conv(num_features, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.gatv22 = GATv2Conv(hidden_channels*heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.gatv23 = GATv2Conv(hidden_channels*heads, out_channels, concat=False,\n",
    "                             heads=1, dropout=dropout)  \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gatv21(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gatv22(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gatv23(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e2fc10d-fc92-4361-965c-a52d8a56cc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GATv2_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GATv2(in_channels=num_features, hidden_channels=32, \n",
    "               out_channels=num_classes, heads=16, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e09c6ac-1350-4aff-9f71-b16b89dbb4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.30, Sup Loss: 2.10, Train Acc: 0.22, Val Loss: 1.92, Val Acc: 0.27\n",
      "Epoch: 015, Con Loss: 9.01, Sup Loss: 2.04, Train Acc: 0.34, Val Loss: 1.86, Val Acc: 0.34\n",
      "Epoch: 030, Con Loss: 8.72, Sup Loss: 2.05, Train Acc: 0.40, Val Loss: 1.80, Val Acc: 0.37\n",
      "Epoch: 045, Con Loss: 8.67, Sup Loss: 1.85, Train Acc: 0.55, Val Loss: 1.62, Val Acc: 0.51\n",
      "Epoch: 060, Con Loss: 8.65, Sup Loss: 1.64, Train Acc: 0.67, Val Loss: 1.38, Val Acc: 0.64\n",
      "Epoch: 075, Con Loss: 8.65, Sup Loss: 1.53, Train Acc: 0.81, Val Loss: 1.19, Val Acc: 0.75\n",
      "Epoch: 090, Con Loss: 8.60, Sup Loss: 1.35, Train Acc: 0.85, Val Loss: 1.05, Val Acc: 0.82\n",
      "Epoch: 105, Con Loss: 8.59, Sup Loss: 1.26, Train Acc: 0.86, Val Loss: 0.93, Val Acc: 0.82\n",
      "Epoch: 120, Con Loss: 8.57, Sup Loss: 1.19, Train Acc: 0.87, Val Loss: 0.84, Val Acc: 0.80\n",
      "Epoch: 135, Con Loss: 8.55, Sup Loss: 1.07, Train Acc: 0.90, Val Loss: 0.76, Val Acc: 0.82\n",
      "Epoch: 150, Con Loss: 8.56, Sup Loss: 1.08, Train Acc: 0.90, Val Loss: 0.70, Val Acc: 0.81\n",
      "Epoch: 165, Con Loss: 8.53, Sup Loss: 1.05, Train Acc: 0.90, Val Loss: 0.66, Val Acc: 0.84\n",
      "Epoch: 180, Con Loss: 8.51, Sup Loss: 0.92, Train Acc: 0.91, Val Loss: 0.63, Val Acc: 0.84\n",
      "Epoch: 195, Con Loss: 8.48, Sup Loss: 0.98, Train Acc: 0.92, Val Loss: 0.60, Val Acc: 0.84\n",
      "Epoch: 210, Con Loss: 8.49, Sup Loss: 0.95, Train Acc: 0.91, Val Loss: 0.58, Val Acc: 0.85\n",
      "Epoch: 225, Con Loss: 8.49, Sup Loss: 0.90, Train Acc: 0.91, Val Loss: 0.57, Val Acc: 0.84\n",
      "Epoch: 240, Con Loss: 8.44, Sup Loss: 0.91, Train Acc: 0.92, Val Loss: 0.55, Val Acc: 0.84\n",
      "Epoch: 255, Con Loss: 8.45, Sup Loss: 0.86, Train Acc: 0.92, Val Loss: 0.54, Val Acc: 0.84\n",
      "Epoch: 270, Con Loss: 8.46, Sup Loss: 0.80, Train Acc: 0.93, Val Loss: 0.53, Val Acc: 0.85\n",
      "Epoch: 285, Con Loss: 8.45, Sup Loss: 0.86, Train Acc: 0.93, Val Loss: 0.53, Val Acc: 0.85\n",
      "Epoch: 300, Con Loss: 8.39, Sup Loss: 0.79, Train Acc: 0.93, Val Loss: 0.53, Val Acc: 0.85\n",
      "Epoch: 315, Con Loss: 8.46, Sup Loss: 0.81, Train Acc: 0.94, Val Loss: 0.52, Val Acc: 0.85\n",
      "Epoch: 330, Con Loss: 8.42, Sup Loss: 0.78, Train Acc: 0.94, Val Loss: 0.51, Val Acc: 0.85\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(GATv2_model, optimizer_lr=0.0004, epoches=345, scheduler_factor=0.3, \n",
    "                            scheduler_patience=1000, output_interval=15, lambda_reg=2)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fbfef9f-4fc4-410f-9a7f-7606ce889d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.800, Val Loss: 0.519\n",
      "Fold 2 - Val Accuracy: 0.778, Val Loss: 0.695\n",
      "Fold 3 - Val Accuracy: 0.889, Val Loss: 0.363\n",
      "Fold 4 - Val Accuracy: 0.879, Val Loss: 0.502\n",
      "Fold 5 - Val Accuracy: 0.838, Val Loss: 0.504\n",
      "Average Val Accuracy: 0.8368, Average Val Loss: 0.5168\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(GATv2_model, optimizer_lr=0.0004, epoches=345, scheduler_factor=0.3, \n",
    "                            scheduler_patience=1000, lambda_reg=2)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26ee6d-04f0-423d-ba61-5e3855b077fb",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd9a526a-fdb0-4a77-8df8-c99e60db0219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TransformerConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73c285c1-f81d-4d84-91b0-e51a20069e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.conv2 = TransformerConv(hidden_channels*heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c73c4d95-8ab3-4763-af1f-22c06146b8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Transformer_model():\n",
    "    torch.manual_seed(123)\n",
    "    return Transformer(in_channels=num_features, hidden_channels=64, \n",
    "               out_channels=num_classes, heads=8, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9abf595-2976-42d3-9438-804595c97c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 10.01, Sup Loss: 1.94, Train Acc: 0.30, Val Loss: 1.91, Val Acc: 0.27\n",
      "Epoch: 015, Con Loss: 8.69, Sup Loss: 1.78, Train Acc: 0.29, Val Loss: 1.83, Val Acc: 0.29\n",
      "Epoch: 030, Con Loss: 8.53, Sup Loss: 1.75, Train Acc: 0.31, Val Loss: 1.82, Val Acc: 0.29\n",
      "Epoch: 045, Con Loss: 8.49, Sup Loss: 1.47, Train Acc: 0.71, Val Loss: 1.55, Val Acc: 0.56\n",
      "Epoch: 060, Con Loss: 8.43, Sup Loss: 1.21, Train Acc: 0.77, Val Loss: 1.29, Val Acc: 0.69\n",
      "Epoch: 075, Con Loss: 8.30, Sup Loss: 0.99, Train Acc: 0.87, Val Loss: 1.08, Val Acc: 0.79\n",
      "Epoch: 090, Con Loss: 8.23, Sup Loss: 0.86, Train Acc: 0.87, Val Loss: 0.92, Val Acc: 0.80\n",
      "Epoch: 105, Con Loss: 8.17, Sup Loss: 0.74, Train Acc: 0.88, Val Loss: 0.83, Val Acc: 0.80\n",
      "Epoch: 120, Con Loss: 8.10, Sup Loss: 0.63, Train Acc: 0.88, Val Loss: 0.76, Val Acc: 0.80\n",
      "Epoch: 135, Con Loss: 8.10, Sup Loss: 0.59, Train Acc: 0.88, Val Loss: 0.71, Val Acc: 0.81\n",
      "Epoch: 150, Con Loss: 8.05, Sup Loss: 0.53, Train Acc: 0.88, Val Loss: 0.67, Val Acc: 0.81\n",
      "Epoch: 165, Con Loss: 7.99, Sup Loss: 0.50, Train Acc: 0.89, Val Loss: 0.63, Val Acc: 0.80\n",
      "Epoch: 180, Con Loss: 8.00, Sup Loss: 0.44, Train Acc: 0.91, Val Loss: 0.60, Val Acc: 0.81\n",
      "Epoch: 195, Con Loss: 7.98, Sup Loss: 0.40, Train Acc: 0.92, Val Loss: 0.58, Val Acc: 0.83\n",
      "Epoch: 210, Con Loss: 7.98, Sup Loss: 0.38, Train Acc: 0.94, Val Loss: 0.56, Val Acc: 0.85\n",
      "Epoch: 225, Con Loss: 7.90, Sup Loss: 0.30, Train Acc: 0.94, Val Loss: 0.55, Val Acc: 0.85\n",
      "Epoch: 240, Con Loss: 7.92, Sup Loss: 0.30, Train Acc: 0.95, Val Loss: 0.54, Val Acc: 0.86\n",
      "Epoch: 255, Con Loss: 7.95, Sup Loss: 0.29, Train Acc: 0.96, Val Loss: 0.53, Val Acc: 0.87\n",
      "Epoch: 270, Con Loss: 7.94, Sup Loss: 0.29, Train Acc: 0.96, Val Loss: 0.53, Val Acc: 0.87\n",
      "Epoch: 285, Con Loss: 7.90, Sup Loss: 0.25, Train Acc: 0.97, Val Loss: 0.52, Val Acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(Transformer_model, optimizer_lr=0.0008, epoches=300, scheduler_factor=0.5, \n",
    "                            scheduler_patience=1000, output_interval=15, lambda_reg=3)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edd38148-94c4-4765-bd97-296257f8a232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.830, Val Loss: 0.530\n",
      "Fold 2 - Val Accuracy: 0.848, Val Loss: 0.585\n",
      "Fold 3 - Val Accuracy: 0.859, Val Loss: 0.388\n",
      "Fold 4 - Val Accuracy: 0.838, Val Loss: 0.465\n",
      "Fold 5 - Val Accuracy: 0.848, Val Loss: 0.513\n",
      "Average Val Accuracy: 0.8448, Average Val Loss: 0.4959\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(Transformer_model, optimizer_lr=0.0008, epoches=300, scheduler_factor=0.5, \n",
    "                            scheduler_patience=1000, lambda_reg=3)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537de2b3-5f9a-4a39-80d4-7830c63d17e3",
   "metadata": {},
   "source": [
    "### APPNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fa07ca4-2893-41cf-83ab-4e5da3589724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import APPNP\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f661cf3-4bc6-4d53-8a63-cb64b1af7c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class APPNP1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, K, alpha, dropout):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "        self.appnp = APPNP(K=K, alpha=alpha, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = self.appnp(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8169e400-5427-42f8-93a0-7847072dbd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def APPNP_model():\n",
    "    torch.manual_seed(123)\n",
    "    return APPNP1(in_channels=num_features, hidden_channels=128, \n",
    "               out_channels=num_classes, K=2, alpha=0.1, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b300b0c-4e2f-4c31-8752-64a3602843cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.57, Sup Loss: 1.95, Train Acc: 0.11, Val Loss: 1.94, Val Acc: 0.12\n",
      "Epoch: 015, Con Loss: 8.51, Sup Loss: 1.96, Train Acc: 0.29, Val Loss: 1.86, Val Acc: 0.30\n",
      "Epoch: 030, Con Loss: 8.50, Sup Loss: 1.83, Train Acc: 0.45, Val Loss: 1.82, Val Acc: 0.43\n",
      "Epoch: 045, Con Loss: 8.49, Sup Loss: 1.76, Train Acc: 0.60, Val Loss: 1.71, Val Acc: 0.51\n",
      "Epoch: 060, Con Loss: 8.48, Sup Loss: 1.60, Train Acc: 0.84, Val Loss: 1.53, Val Acc: 0.78\n",
      "Epoch: 075, Con Loss: 8.45, Sup Loss: 1.49, Train Acc: 0.90, Val Loss: 1.33, Val Acc: 0.81\n",
      "Epoch: 090, Con Loss: 8.46, Sup Loss: 1.54, Train Acc: 0.90, Val Loss: 1.16, Val Acc: 0.82\n",
      "Epoch: 105, Con Loss: 8.43, Sup Loss: 1.39, Train Acc: 0.92, Val Loss: 1.04, Val Acc: 0.86\n",
      "Epoch: 120, Con Loss: 8.43, Sup Loss: 1.45, Train Acc: 0.93, Val Loss: 0.93, Val Acc: 0.85\n",
      "Epoch: 135, Con Loss: 8.42, Sup Loss: 1.42, Train Acc: 0.94, Val Loss: 0.85, Val Acc: 0.84\n",
      "Epoch: 150, Con Loss: 8.42, Sup Loss: 1.30, Train Acc: 0.95, Val Loss: 0.77, Val Acc: 0.85\n",
      "Epoch: 165, Con Loss: 8.41, Sup Loss: 1.25, Train Acc: 0.94, Val Loss: 0.71, Val Acc: 0.85\n",
      "Epoch: 180, Con Loss: 8.40, Sup Loss: 1.24, Train Acc: 0.96, Val Loss: 0.66, Val Acc: 0.85\n",
      "Epoch: 195, Con Loss: 8.41, Sup Loss: 1.23, Train Acc: 0.96, Val Loss: 0.61, Val Acc: 0.85\n",
      "Epoch: 210, Con Loss: 8.41, Sup Loss: 1.21, Train Acc: 0.97, Val Loss: 0.57, Val Acc: 0.87\n",
      "Epoch: 225, Con Loss: 8.40, Sup Loss: 1.19, Train Acc: 0.97, Val Loss: 0.55, Val Acc: 0.86\n",
      "Epoch: 240, Con Loss: 8.40, Sup Loss: 1.24, Train Acc: 0.97, Val Loss: 0.53, Val Acc: 0.86\n",
      "Epoch: 255, Con Loss: 8.40, Sup Loss: 1.05, Train Acc: 0.97, Val Loss: 0.51, Val Acc: 0.86\n",
      "Epoch: 270, Con Loss: 8.40, Sup Loss: 1.19, Train Acc: 0.97, Val Loss: 0.50, Val Acc: 0.86\n",
      "Epoch: 285, Con Loss: 8.42, Sup Loss: 1.09, Train Acc: 0.98, Val Loss: 0.48, Val Acc: 0.87\n",
      "Epoch: 300, Con Loss: 8.39, Sup Loss: 1.06, Train Acc: 0.98, Val Loss: 0.47, Val Acc: 0.86\n",
      "Epoch: 315, Con Loss: 8.41, Sup Loss: 1.08, Train Acc: 0.98, Val Loss: 0.47, Val Acc: 0.86\n",
      "Epoch: 330, Con Loss: 8.39, Sup Loss: 0.97, Train Acc: 0.98, Val Loss: 0.47, Val Acc: 0.88\n",
      "Epoch: 345, Con Loss: 8.40, Sup Loss: 1.16, Train Acc: 0.98, Val Loss: 0.47, Val Acc: 0.86\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(APPNP_model, optimizer_lr=0.005, epoches=360, scheduler_factor=0.4, \n",
    "                            scheduler_patience=1000, output_interval=15, lambda_reg=3)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b175e60-3eb9-43e2-a60c-0c1ec8c4e931",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.800, Val Loss: 0.518\n",
      "Fold 2 - Val Accuracy: 0.818, Val Loss: 0.689\n",
      "Fold 3 - Val Accuracy: 0.859, Val Loss: 0.398\n",
      "Fold 4 - Val Accuracy: 0.838, Val Loss: 0.482\n",
      "Fold 5 - Val Accuracy: 0.838, Val Loss: 0.513\n",
      "Average Val Accuracy: 0.8307, Average Val Loss: 0.5199\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(APPNP_model, optimizer_lr=0.005, epoches=360, scheduler_factor=0.4, \n",
    "                            scheduler_patience=1000, lambda_reg=3)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d5565-3b9e-4df7-9f14-51563f0e3444",
   "metadata": {},
   "source": [
    "### ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74e66f7d-3899-4387-a2e4-c953ba38c9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b27876e8-bf68-4ac6-a0d1-834b3f782a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChebConvModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, K):\n",
    "        super(ChebConvModel, self).__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K)\n",
    "        self.conv2 = ChebConv(hidden_channels, out_channels, K)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3f11083-18a1-43ee-b087-f1160bd4014e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ChebConv_model():\n",
    "    torch.manual_seed(123)\n",
    "    return ChebConvModel(in_channels=num_features, hidden_channels=256,\n",
    "               out_channels=num_classes, K=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b31ee9d0-e4ac-4c9e-95a5-564b6bf0eaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.90, Sup Loss: 2.05, Train Acc: 0.21, Val Loss: 1.95, Val Acc: 0.21\n",
      "Epoch: 013, Con Loss: 9.69, Sup Loss: 1.50, Train Acc: 0.57, Val Loss: 1.56, Val Acc: 0.43\n",
      "Epoch: 026, Con Loss: 9.22, Sup Loss: 1.18, Train Acc: 0.64, Val Loss: 1.38, Val Acc: 0.52\n",
      "Epoch: 039, Con Loss: 9.01, Sup Loss: 0.92, Train Acc: 0.81, Val Loss: 1.16, Val Acc: 0.65\n",
      "Epoch: 052, Con Loss: 8.80, Sup Loss: 0.71, Train Acc: 0.88, Val Loss: 0.94, Val Acc: 0.77\n",
      "Epoch: 065, Con Loss: 8.69, Sup Loss: 0.51, Train Acc: 0.89, Val Loss: 0.79, Val Acc: 0.83\n",
      "Epoch: 078, Con Loss: 8.55, Sup Loss: 0.42, Train Acc: 0.91, Val Loss: 0.69, Val Acc: 0.83\n",
      "Epoch: 091, Con Loss: 8.47, Sup Loss: 0.34, Train Acc: 0.94, Val Loss: 0.63, Val Acc: 0.83\n",
      "Epoch: 104, Con Loss: 8.43, Sup Loss: 0.28, Train Acc: 0.95, Val Loss: 0.58, Val Acc: 0.82\n",
      "Epoch: 117, Con Loss: 8.30, Sup Loss: 0.23, Train Acc: 0.97, Val Loss: 0.55, Val Acc: 0.83\n",
      "Epoch: 130, Con Loss: 8.28, Sup Loss: 0.19, Train Acc: 0.97, Val Loss: 0.52, Val Acc: 0.85\n",
      "Epoch: 143, Con Loss: 8.25, Sup Loss: 0.18, Train Acc: 0.98, Val Loss: 0.51, Val Acc: 0.85\n",
      "Epoch: 156, Con Loss: 8.19, Sup Loss: 0.16, Train Acc: 0.98, Val Loss: 0.50, Val Acc: 0.85\n",
      "Epoch: 169, Con Loss: 8.11, Sup Loss: 0.15, Train Acc: 0.98, Val Loss: 0.49, Val Acc: 0.85\n",
      "Epoch: 182, Con Loss: 8.13, Sup Loss: 0.13, Train Acc: 0.99, Val Loss: 0.49, Val Acc: 0.85\n",
      "Epoch: 195, Con Loss: 7.98, Sup Loss: 0.11, Train Acc: 0.99, Val Loss: 0.49, Val Acc: 0.85\n",
      "Epoch: 208, Con Loss: 8.07, Sup Loss: 0.11, Train Acc: 0.99, Val Loss: 0.49, Val Acc: 0.86\n",
      "Epoch: 221, Con Loss: 8.04, Sup Loss: 0.11, Train Acc: 0.99, Val Loss: 0.49, Val Acc: 0.86\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(ChebConv_model, optimizer_lr=0.0005, epoches=230, scheduler_factor=0.5,\n",
    "                            scheduler_patience=1000, output_interval=13, lambda_reg=1.5)\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3099334d-0df1-4ce8-86bd-f220d6a346b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Val Accuracy: 0.810, Val Loss: 0.604\n",
      "Fold 2 - Val Accuracy: 0.838, Val Loss: 0.535\n",
      "Fold 3 - Val Accuracy: 0.899, Val Loss: 0.400\n",
      "Fold 4 - Val Accuracy: 0.848, Val Loss: 0.552\n",
      "Fold 5 - Val Accuracy: 0.828, Val Loss: 0.564\n",
      "Average Val Accuracy: 0.8448, Average Val Loss: 0.5310\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(ChebConv_model, optimizer_lr=0.0005, epoches=230, scheduler_factor=0.5,\n",
    "                            scheduler_patience=1000, lambda_reg=1.5)\n",
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
