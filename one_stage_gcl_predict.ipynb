{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f44b5b0-f8ba-44a9-87e5-10ea895601f5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b078888-89ff-480e-8ba0-aed18a243e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*'dropout_adj' is deprecated, use 'dropout_edge' instead.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3b8846-26c4-4b65-b231-a91c76dba465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b282aa-6c67-4bda-b42d-f50922f1dcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "adj = sp.load_npz('../CSE881_data_2024/adj.npz')\n",
    "features  = np.load('../CSE881_data_2024/features.npy')\n",
    "labels = np.load('../CSE881_data_2024/labels.npy')\n",
    "splits = json.load(open('../CSE881_data_2024/splits.json'))\n",
    "idx_train, idx_test = splits['idx_train'], splits['idx_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cec296-91e8-4c19-a07c-247f5521a7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10100 edges in total in the graph\n",
      "\n",
      "tensor([1.])\n",
      "These edges are not weighted.\n"
     ]
    }
   ],
   "source": [
    "# transfer adjacency matrix into edge index\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "edge_index = from_scipy_sparse_matrix(adj)\n",
    "print(\"There are\", edge_index[0].size(1), \"edges in total in the graph\\n\")\n",
    "\n",
    "print(torch.unique(edge_index[1]))\n",
    "print(\"These edges are not weighted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48aba824-8a75-4e6c-b9e5-cdd7806172d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2480 nodes in the graph.\n",
      "Each node can be one of 7 classes.\n",
      "Training set size: 496\n",
      "Test set size: 1984\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(features), \"nodes in the graph.\")\n",
    "num_classes = len(np.unique(labels))\n",
    "print(\"Each node can be one of\", num_classes, \"classes.\")\n",
    "print(\"Training set size:\", len(idx_train))\n",
    "print(\"Test set size:\", len(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b743263-a811-4f48-bd0c-ea1dfa407d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136d32c6-ae9d-4c59-957b-21641468fd57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1390\n"
     ]
    }
   ],
   "source": [
    "features = torch.from_numpy(features).float()\n",
    "num_features = len(features[0])\n",
    "print(\"Number of features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0a8f6c-bebf-49c5-a66c-ec842cbfed9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = features.to(device)\n",
    "edge_index = edge_index[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7d16f-36fb-483f-bb3f-ffa1063fd704",
   "metadata": {},
   "source": [
    "### Supurvised Contrastive Learning Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46408102-4ba8-476a-9e0c-baf18123335f",
   "metadata": {},
   "source": [
    "Method 'GRACE': Zhu et al., Deep Graph Contrastive Representation Learning, GRL+@ICML, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d38b3-16d7-47a1-b726-8bb8b11150c3",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2006.04131"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac53a84-1022-4ae7-bea2-5edffe136929",
   "metadata": {},
   "source": [
    "Method 'SupCon': P. Khosla et al., Supervised Contrastive Learning, NeurIPS, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca794ac-460b-46d2-8c8a-9c620df143e3",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/2004.11362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7154e4b-bdd9-43a4-9083-6de21c949e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import GCL.augmentors as A\n",
    "import GCL.losses as L\n",
    "from GCL.models import DualBranchContrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf7e5dd-1730-4751-b56a-72dd6dced667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, augmentor):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.augmentor = augmentor\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        aug1, aug2 = self.augmentor\n",
    "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
    "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
    "        z = self.encoder(x, edge_index)\n",
    "        z1 = self.encoder(x1, edge_index1)\n",
    "        z2 = self.encoder(x2, edge_index2)\n",
    "        return z, z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4905cc4b-9dc6-4ff9-97d8-fb85d9a6b2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contrastive_mask(idx, labels):\n",
    "    \n",
    "    num_nodes = len(features)\n",
    "\n",
    "    # create extra_pos_mask\n",
    "    # initialize a 2480 x 2480 matrix of False\n",
    "    extra_pos_mask = torch.zeros((num_nodes, num_nodes), dtype=torch.bool).to(device)\n",
    "\n",
    "    # create a temporary full label tensor initialized with a dummy label and place the known labels\n",
    "    full_labels = torch.full((num_nodes,), -1, dtype=labels.dtype).to(device)\n",
    "    full_labels[idx] = labels\n",
    "\n",
    "    # iterate through each known label and update the label_matrix to True by finding nodes with the same label\n",
    "    for i, label in zip(idx, labels):\n",
    "        same_label_indices = torch.where(full_labels == label)[0]\n",
    "        extra_pos_mask[i, same_label_indices] = True\n",
    "        extra_pos_mask[same_label_indices, i] = True\n",
    "    extra_pos_mask.fill_diagonal_(False)\n",
    "\n",
    "    # pos_mask: [N, 2N] for both inter-view and intra-view samples\n",
    "    extra_pos_mask = torch.cat([extra_pos_mask, extra_pos_mask], dim=1).to(device)\n",
    "    # fill inter-view positives only; pos_mask for intra-view samples should have False in diagonal\n",
    "    extra_pos_mask.fill_diagonal_(True)\n",
    "\n",
    "    # create extra_neg_mask\n",
    "    # initialize a 2480 x 2480 matrix of True\n",
    "    extra_neg_mask = torch.ones((num_nodes, num_nodes), dtype=torch.bool).to(device)\n",
    "\n",
    "    # iterate through each known label and update the label_matrix to False by finding nodes with the same label\n",
    "    for i, label in zip(idx, labels):\n",
    "        same_label_indices = torch.where(full_labels == label)[0]\n",
    "        extra_neg_mask[i, same_label_indices] = False\n",
    "        extra_neg_mask[same_label_indices, i] = False\n",
    "\n",
    "    # set the diagonal to False since a sample cannot be a negative of itself\n",
    "    extra_neg_mask.fill_diagonal_(False)\n",
    "\n",
    "    # neg_mask: [N, 2N] for both inter-view and intra-view samples\n",
    "    extra_neg_mask = torch.cat([extra_neg_mask, extra_neg_mask], dim=1).to(device)\n",
    "    \n",
    "    return extra_pos_mask, extra_neg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b04ffe-fb7e-4881-8c20-105b307beea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augumentation of the graph\n",
    "aug1 = A.Compose([A.EdgeRemoving(pe=0.1), A.FeatureDropout(pf=0.1), A.NodeDropping(pn=0.1)])\n",
    "aug2 = A.Compose([A.EdgeRemoving(pe=0.1), A.FeatureDropout(pf=0.1), A.NodeDropping(pn=0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36af2c84-221e-4684-938d-0616ea7ed66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# contrastive loss function\n",
    "contrast_loss = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='L2L', intraview_negs=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73852b5d-71d8-4cf0-9258-dd2a233b3ed8",
   "metadata": {},
   "source": [
    "### Result Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e01b66-cd07-4227-bd7e-565c554b2ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResultPredictor:\n",
    "    def __init__(self, model_structure, optimizer_lr, epoches, lambda_reg, output_interval=4, \n",
    "                 features=features, edge_index=edge_index, labels=labels, idx=idx_train, method='SupCon'):\n",
    "        \"\"\"\n",
    "        Used for hyperparameter tuning with spliting 20% of training set as validation set\n",
    "        \n",
    "        :param model_structure: The function to define model structure\n",
    "        :param optimizer_lr: The initial learning rate for the optimizer\n",
    "        :param epoches: The number of epoches to train\n",
    "        :param lambda_reg: Hyperparameter to control ratio of contrastive loss\n",
    "        :param output_interval: The interval to ouput the training result\n",
    "        :param features: The features of the dataset\n",
    "        :param edge_index: The edge index tensor describing graph connectivity\n",
    "        :param labels: The labels for training data in the dataset\n",
    "        :param idx: Indices of the training dataset\n",
    "        :param method: Contrastive learning method: SupCon or GRACE\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_structure = model_structure\n",
    "        self.model = self.model_structure() \n",
    "        \n",
    "        self.optimizer_lr = optimizer_lr\n",
    "        self.epoches = epoches\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        self.output_interval = output_interval\n",
    "        self.features = features\n",
    "        self.edge_index = edge_index\n",
    "        self.labels = labels\n",
    "        self.idx = idx\n",
    "        self.method = method\n",
    "        \n",
    "        # Converting labels to tensor\n",
    "        self.labels = torch.from_numpy(self.labels).long().to(device)\n",
    "        \n",
    "        self.encoder_model = Encoder(encoder=self.model, augmentor=(aug1, aug2)).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.encoder_model.parameters(), optimizer_lr)\n",
    "        \n",
    "        self.supervised_criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.contrast_criterion = contrast_loss\n",
    "        self.extra_pos_mask, self.extra_neg_mask = contrastive_mask(self.idx, self.labels)\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model on the training dataset.\n",
    "        \"\"\"\n",
    "        self.encoder_model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        z, z1, z2 = self.encoder_model(self.features, self.edge_index)\n",
    "        \n",
    "        if self.method == 'SupCon':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2, extra_pos_mask=self.extra_pos_mask, extra_neg_mask=self.extra_neg_mask)\n",
    "        elif self.method == 'GRACE':\n",
    "            contrast_loss = self.contrast_criterion(h1=z1, h2=z2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method specified. Please choose 'SupCon' or 'GRACE'.\")\n",
    "        supervised_loss = self.supervised_criterion(z[self.idx], self.labels)\n",
    "        \n",
    "        total_loss = supervised_loss + self.lambda_reg * contrast_loss\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return contrast_loss, supervised_loss\n",
    "    \n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Evaluates the train accuracy.\n",
    "        \"\"\"\n",
    "        self.encoder_model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.encoder_model(self.features, self.edge_index)\n",
    "            pred = out[0].argmax(dim=1)\n",
    "            \n",
    "            train_correct = pred[self.idx] == self.labels\n",
    "            train_acc = int(train_correct.sum()) / len(self.idx)\n",
    "            \n",
    "        return train_acc\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executes the training and validation process, adjusting the learning rate and lambda as needed.\n",
    "        \"\"\"   \n",
    "        for epoch in range(self.epoches):\n",
    "            contrast_loss, supervised_loss = self.train()\n",
    "            train_acc = self.test()\n",
    "            \n",
    "            if epoch % self.output_interval == 0:\n",
    "                print(f'Epoch: {epoch:03d}, Con Loss: {contrast_loss:.2f}, Sup Loss: {supervised_loss:.2f}, Train Acc: {train_acc:.2f}')\n",
    "        \n",
    "        return self.encoder_model\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "    tuner = HyperparameterTuner(model_structure, optimizer_lr=0.001, \n",
    "    epoches=100, lambda=0.9, output_interval=4, features=features, \n",
    "    edge_index_tensor=edge_index_tensor, labels=labels, idx=idx_train, \n",
    "    method='SupCon')\n",
    "    tuner.run()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324aa4a5-1281-4e3d-a014-33309702d59e",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be66fee1-2315-4090-b3ba-3b6cf4dddd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a396bdaf-f90e-4bbe-8710-b7ec91ad4c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GCN_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GCN(in_channels=num_features, hidden_channels=512, \n",
    "               out_channels=num_classes, num_layers=3, dropout=0.5, act='relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352064e5-e57b-47d7-8ef9-a0b60b7a0aac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.22, Sup Loss: 1.94, Train Acc: 0.15\n",
      "Epoch: 020, Con Loss: 8.50, Sup Loss: 1.83, Train Acc: 0.15\n",
      "Epoch: 040, Con Loss: 8.45, Sup Loss: 1.54, Train Acc: 0.57\n",
      "Epoch: 060, Con Loss: 8.01, Sup Loss: 1.08, Train Acc: 0.71\n",
      "Epoch: 080, Con Loss: 7.84, Sup Loss: 0.77, Train Acc: 0.74\n",
      "Epoch: 100, Con Loss: 7.68, Sup Loss: 0.60, Train Acc: 0.85\n",
      "Epoch: 120, Con Loss: 7.65, Sup Loss: 0.48, Train Acc: 0.86\n",
      "Epoch: 140, Con Loss: 7.58, Sup Loss: 0.39, Train Acc: 0.89\n",
      "Epoch: 160, Con Loss: 7.51, Sup Loss: 0.34, Train Acc: 0.92\n",
      "Epoch: 180, Con Loss: 7.55, Sup Loss: 0.30, Train Acc: 0.92\n",
      "Epoch: 200, Con Loss: 7.46, Sup Loss: 0.26, Train Acc: 0.93\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(GCN_model, optimizer_lr=0.0005, epoches=210, lambda_reg=2, output_interval=20)\n",
    "GCN_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe242af-6bf2-416e-b3f2-88529e0cbf30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): GCN(1390, 7, num_layers=3)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e4f85-fa21-4f55-bae5-c4785f5941c3",
   "metadata": {},
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4858d5f8-f4fb-4db7-8bbe-e15f6317f05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ab3ee2-f4d2-45dc-9baa-7c9fb18a9273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GraphSAGE_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GraphSAGE(in_channels=num_features, hidden_channels=256, \n",
    "               out_channels=num_classes, num_layers=3, dropout=0.5, act='relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b07b72b-6f7a-4379-aba3-917012e4bdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.13, Sup Loss: 1.96, Train Acc: 0.05\n",
      "Epoch: 020, Con Loss: 8.52, Sup Loss: 1.96, Train Acc: 0.10\n",
      "Epoch: 040, Con Loss: 8.50, Sup Loss: 1.88, Train Acc: 0.27\n",
      "Epoch: 060, Con Loss: 8.41, Sup Loss: 1.66, Train Acc: 0.76\n",
      "Epoch: 080, Con Loss: 8.06, Sup Loss: 1.06, Train Acc: 0.89\n",
      "Epoch: 100, Con Loss: 7.89, Sup Loss: 0.53, Train Acc: 0.88\n",
      "Epoch: 120, Con Loss: 7.82, Sup Loss: 0.35, Train Acc: 0.92\n",
      "Epoch: 140, Con Loss: 7.74, Sup Loss: 0.27, Train Acc: 0.93\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(GraphSAGE_model, optimizer_lr=0.0003, epoches=145, lambda_reg=0.8, output_interval=20)\n",
    "GraphSAGE_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75842773-23b2-47b8-84ed-af49216b6dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): GraphSAGE(1390, 7, num_layers=3)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphSAGE_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7ab93-db34-4320-8b37-faec30960d03",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa5964c-cbdf-40e7-b555-d5cce3daa8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e2f7af1-3c03-4529-8364-62472a5056ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout) \n",
    "        self.gat2 = GATConv(hidden_channels*heads, hidden_channels, heads=heads, dropout=dropout) \n",
    "        self.gat3 = GATConv(hidden_channels*heads, out_channels, concat=False,\n",
    "                             heads=1, dropout=dropout)  \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gat3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd53b4a-17f0-4305-aa16-0cbc62dc0167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GAT_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GAT(in_channels=num_features, hidden_channels=32, \n",
    "               out_channels=num_classes, heads=16, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "542a75f0-6e67-4083-b051-6949a80b56e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.27, Sup Loss: 2.08, Train Acc: 0.35\n",
      "Epoch: 008, Con Loss: 9.71, Sup Loss: 1.61, Train Acc: 0.71\n",
      "Epoch: 016, Con Loss: 9.56, Sup Loss: 1.21, Train Acc: 0.83\n",
      "Epoch: 024, Con Loss: 9.58, Sup Loss: 1.08, Train Acc: 0.88\n",
      "Epoch: 032, Con Loss: 9.36, Sup Loss: 0.97, Train Acc: 0.91\n",
      "Epoch: 040, Con Loss: 9.32, Sup Loss: 0.89, Train Acc: 0.91\n",
      "Epoch: 048, Con Loss: 9.30, Sup Loss: 0.80, Train Acc: 0.92\n",
      "Epoch: 056, Con Loss: 9.29, Sup Loss: 0.83, Train Acc: 0.92\n",
      "Epoch: 064, Con Loss: 9.22, Sup Loss: 0.72, Train Acc: 0.94\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(GAT_model, optimizer_lr=0.0008, epoches=67, lambda_reg=0, output_interval=8)\n",
    "GAT_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd3950b5-8bbf-4499-a805-b02e39eff484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): GAT(\n",
       "    (gat1): GATConv(1390, 32, heads=16)\n",
       "    (gat2): GATConv(512, 32, heads=16)\n",
       "    (gat3): GATConv(512, 7, heads=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAT_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33f12f-06a7-438f-ba81-accd16ce02f9",
   "metadata": {},
   "source": [
    "### GAT - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a4dcc59-b431-4c64-b339-8e3cab59eddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfee795d-feb2-40e6-bcfb-a22749090fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.gatv21 = GATv2Conv(num_features, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.gatv22 = GATv2Conv(hidden_channels*heads, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.gatv23 = GATv2Conv(hidden_channels*heads, out_channels, concat=False,\n",
    "                             heads=1, dropout=dropout)  \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gatv21(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gatv22(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.gatv23(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e2fc10d-fc92-4361-965c-a52d8a56cc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GATv2_model():\n",
    "    torch.manual_seed(123)\n",
    "    return GATv2(in_channels=num_features, hidden_channels=32, \n",
    "               out_channels=num_classes, heads=16, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e09c6ac-1350-4aff-9f71-b16b89dbb4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.30, Sup Loss: 2.09, Train Acc: 0.23\n",
      "Epoch: 035, Con Loss: 8.70, Sup Loss: 1.93, Train Acc: 0.45\n",
      "Epoch: 070, Con Loss: 8.64, Sup Loss: 1.45, Train Acc: 0.78\n",
      "Epoch: 105, Con Loss: 8.59, Sup Loss: 1.27, Train Acc: 0.86\n",
      "Epoch: 140, Con Loss: 8.54, Sup Loss: 1.06, Train Acc: 0.89\n",
      "Epoch: 175, Con Loss: 8.52, Sup Loss: 1.05, Train Acc: 0.90\n",
      "Epoch: 210, Con Loss: 8.49, Sup Loss: 0.96, Train Acc: 0.90\n",
      "Epoch: 245, Con Loss: 8.43, Sup Loss: 0.88, Train Acc: 0.91\n",
      "Epoch: 280, Con Loss: 8.45, Sup Loss: 0.90, Train Acc: 0.92\n",
      "Epoch: 315, Con Loss: 8.46, Sup Loss: 0.81, Train Acc: 0.93\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(GATv2_model, optimizer_lr=0.0004, epoches=345, lambda_reg=2, output_interval=35)\n",
    "GATv2_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fbfef9f-4fc4-410f-9a7f-7606ce889d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): GATv2(\n",
       "    (gatv21): GATv2Conv(1390, 32, heads=16)\n",
       "    (gatv22): GATv2Conv(512, 32, heads=16)\n",
       "    (gatv23): GATv2Conv(512, 7, heads=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GATv2_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26ee6d-04f0-423d-ba61-5e3855b077fb",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd9a526a-fdb0-4a77-8df8-c99e60db0219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TransformerConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73c285c1-f81d-4d84-91b0-e51a20069e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = TransformerConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.conv2 = TransformerConv(hidden_channels*heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73c4d95-8ab3-4763-af1f-22c06146b8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Transformer_model():\n",
    "    torch.manual_seed(123)\n",
    "    return Transformer(in_channels=num_features, hidden_channels=64, \n",
    "               out_channels=num_classes, heads=8, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9abf595-2976-42d3-9438-804595c97c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 10.01, Sup Loss: 1.94, Train Acc: 0.30\n",
      "Epoch: 028, Con Loss: 8.55, Sup Loss: 1.79, Train Acc: 0.30\n",
      "Epoch: 056, Con Loss: 8.45, Sup Loss: 1.27, Train Acc: 0.76\n",
      "Epoch: 084, Con Loss: 8.29, Sup Loss: 0.89, Train Acc: 0.86\n",
      "Epoch: 112, Con Loss: 8.10, Sup Loss: 0.69, Train Acc: 0.86\n",
      "Epoch: 140, Con Loss: 8.07, Sup Loss: 0.58, Train Acc: 0.87\n",
      "Epoch: 168, Con Loss: 7.98, Sup Loss: 0.51, Train Acc: 0.89\n",
      "Epoch: 196, Con Loss: 8.01, Sup Loss: 0.42, Train Acc: 0.92\n",
      "Epoch: 224, Con Loss: 8.01, Sup Loss: 0.35, Train Acc: 0.92\n",
      "Epoch: 252, Con Loss: 7.98, Sup Loss: 0.31, Train Acc: 0.94\n",
      "Epoch: 280, Con Loss: 7.94, Sup Loss: 0.29, Train Acc: 0.95\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(Transformer_model, optimizer_lr=0.0008, epoches=300, lambda_reg=3, output_interval=28)\n",
    "Transformer_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edd38148-94c4-4765-bd97-296257f8a232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Transformer(\n",
       "    (conv1): TransformerConv(1390, 64, heads=8)\n",
       "    (conv2): TransformerConv(512, 7, heads=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537de2b3-5f9a-4a39-80d4-7830c63d17e3",
   "metadata": {},
   "source": [
    "### APPNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fa07ca4-2893-41cf-83ab-4e5da3589724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import APPNP\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f661cf3-4bc6-4d53-8a63-cb64b1af7c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class APPNP1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, K, alpha, dropout):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "        self.appnp = APPNP(K=K, alpha=alpha, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = self.appnp(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8169e400-5427-42f8-93a0-7847072dbd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def APPNP_model():\n",
    "    torch.manual_seed(123)\n",
    "    return APPNP1(in_channels=num_features, hidden_channels=128, \n",
    "               out_channels=num_classes, K=2, alpha=0.1, dropout=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b300b0c-4e2f-4c31-8752-64a3602843cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.58, Sup Loss: 1.95, Train Acc: 0.11\n",
      "Epoch: 028, Con Loss: 8.50, Sup Loss: 1.83, Train Acc: 0.45\n",
      "Epoch: 056, Con Loss: 8.48, Sup Loss: 1.64, Train Acc: 0.82\n",
      "Epoch: 084, Con Loss: 8.44, Sup Loss: 1.40, Train Acc: 0.90\n",
      "Epoch: 112, Con Loss: 8.44, Sup Loss: 1.39, Train Acc: 0.91\n",
      "Epoch: 140, Con Loss: 8.44, Sup Loss: 1.39, Train Acc: 0.94\n",
      "Epoch: 168, Con Loss: 8.42, Sup Loss: 1.31, Train Acc: 0.95\n",
      "Epoch: 196, Con Loss: 8.41, Sup Loss: 1.32, Train Acc: 0.95\n",
      "Epoch: 224, Con Loss: 8.40, Sup Loss: 1.16, Train Acc: 0.96\n",
      "Epoch: 252, Con Loss: 8.42, Sup Loss: 1.25, Train Acc: 0.97\n",
      "Epoch: 280, Con Loss: 8.40, Sup Loss: 1.20, Train Acc: 0.97\n",
      "Epoch: 308, Con Loss: 8.40, Sup Loss: 1.13, Train Acc: 0.97\n",
      "Epoch: 336, Con Loss: 8.41, Sup Loss: 1.12, Train Acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(APPNP_model, optimizer_lr=0.005, epoches=360, lambda_reg=3, output_interval=28)\n",
    "APPNP_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b175e60-3eb9-43e2-a60c-0c1ec8c4e931",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): APPNP1(\n",
       "    (lin1): Linear(in_features=1390, out_features=128, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=7, bias=True)\n",
       "    (appnp): APPNP(K=2, alpha=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPNP_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d5565-3b9e-4df7-9f14-51563f0e3444",
   "metadata": {},
   "source": [
    "### ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74e66f7d-3899-4387-a2e4-c953ba38c9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b27876e8-bf68-4ac6-a0d1-834b3f782a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChebConvModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, K):\n",
    "        super(ChebConvModel, self).__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K)\n",
    "        self.conv2 = ChebConv(hidden_channels, out_channels, K)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3f11083-18a1-43ee-b087-f1160bd4014e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ChebConv_model():\n",
    "    torch.manual_seed(123)\n",
    "    return ChebConvModel(in_channels=num_features, hidden_channels=256,\n",
    "               out_channels=num_classes, K=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b31ee9d0-e4ac-4c9e-95a5-564b6bf0eaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Con Loss: 9.91, Sup Loss: 2.04, Train Acc: 0.22\n",
      "Epoch: 020, Con Loss: 9.42, Sup Loss: 1.34, Train Acc: 0.53\n",
      "Epoch: 040, Con Loss: 8.98, Sup Loss: 0.93, Train Acc: 0.81\n",
      "Epoch: 060, Con Loss: 8.70, Sup Loss: 0.58, Train Acc: 0.88\n",
      "Epoch: 080, Con Loss: 8.60, Sup Loss: 0.43, Train Acc: 0.91\n",
      "Epoch: 100, Con Loss: 8.41, Sup Loss: 0.30, Train Acc: 0.94\n",
      "Epoch: 120, Con Loss: 8.28, Sup Loss: 0.25, Train Acc: 0.96\n",
      "Epoch: 140, Con Loss: 8.24, Sup Loss: 0.20, Train Acc: 0.96\n",
      "Epoch: 160, Con Loss: 8.15, Sup Loss: 0.17, Train Acc: 0.97\n",
      "Epoch: 180, Con Loss: 8.10, Sup Loss: 0.15, Train Acc: 0.98\n",
      "Epoch: 200, Con Loss: 8.10, Sup Loss: 0.14, Train Acc: 0.98\n",
      "Epoch: 220, Con Loss: 8.02, Sup Loss: 0.12, Train Acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "predictor = ResultPredictor(ChebConv_model, optimizer_lr=0.0005, epoches=230, lambda_reg=1.5, output_interval=20)\n",
    "ChebConv_model = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3099334d-0df1-4ce8-86bd-f220d6a346b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): ChebConvModel(\n",
       "    (conv1): ChebConv(1390, 256, K=2, normalization=sym)\n",
       "    (conv2): ChebConv(256, 7, K=2, normalization=sym)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChebConv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea0c79-dfd9-4d42-914f-e491974a82a4",
   "metadata": {},
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7f54c2c-009d-4cca-a59e-5e86776d0808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCN_accuracy = 0.8488\n",
    "GraphSAGE_accuracy = 0.8448\n",
    "GAT_accuracy = 0.8408\n",
    "GATv2_accuracy = 0.8368\n",
    "Transformer_accuracy = 0.8448\n",
    "APPNP_accuracy = 0.8307\n",
    "ChebConv_accuracy = 0.8448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88864454-2b3c-4207-9f17-172298433259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_group = [GCN_model, GraphSAGE_model, GAT_model, GATv2_model,\n",
    "               Transformer_model, APPNP_model, ChebConv_model]\n",
    "model_accuracy = [GCN_accuracy, GraphSAGE_accuracy, GAT_accuracy, GATv2_accuracy,\n",
    "               Transformer_accuracy, APPNP_accuracy, ChebConv_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e5df8a8-80c4-4274-be51-7bb8bd925969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_nodes = len(features)\n",
    "num_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "468a63db-b533-4801-a9b0-ff22934919d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_voting(model_group, model_accuracy, num_nodes, num_classes, features, edge_index):\n",
    "    votes = np.zeros((num_nodes, num_classes))\n",
    "    group_contributions = {}\n",
    "    group_names = [\"GCN\", \"GraphSAGE\", \"GAT\", \"GATv2\", \"Transformer\", \"APPNP\", \"ChebConv\"]\n",
    "\n",
    "    for i, model in enumerate(model_group):\n",
    "        accuracy = model_accuracy[i]\n",
    "        group_name = group_names[i]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(features, edge_index)\n",
    "            pred_probs = F.softmax(out[0], dim=1).cpu().numpy()\n",
    "            weighted_pred_probs = pred_probs * accuracy\n",
    "            votes += weighted_pred_probs  \n",
    "\n",
    "        group_contributions[group_name] = np.argmax(weighted_pred_probs, axis=1)\n",
    "\n",
    "    final_predictions = np.argmax(votes, axis=1)\n",
    "    contribution_counts = {group_name: np.sum(group_contributions[group_name] == final_predictions) for group_name in group_contributions}\n",
    "\n",
    "    return final_predictions, contribution_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0e81777-d241-4f45-b5ae-adbad7891129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions, contribution_counts = weighted_voting(model_group, model_accuracy, num_nodes, \n",
    "                                                           num_classes, features, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99a84a68-b032-4506-bfba-21c0abc9a3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 1, 1, 2, 3, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions[idx_test][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f47124a3-424c-4839-87e6-97b36191bd09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GCN': 2360,\n",
       " 'GraphSAGE': 2400,\n",
       " 'GAT': 2356,\n",
       " 'GATv2': 2374,\n",
       " 'Transformer': 2368,\n",
       " 'APPNP': 2367,\n",
       " 'ChebConv': 2367}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d0006a3-b7cf-4712-8605-db45c57f079c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637096774193549"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_predictions[idx_train] == labels).sum().item() / len(idx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c27f3561-3864-4460-8514-6973b270374a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = final_predictions[idx_test]\n",
    "np.savetxt('submission4.txt', preds, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
